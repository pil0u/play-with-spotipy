{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Spotify authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(\n",
    "  client_id=os.environ.get(\"SPOTIFY_CLIENT_ID\"),\n",
    "  client_secret=os.environ.get(\"SPOTIFY_CLIENT_SECRET\")\n",
    ")\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1: Retrieve 1000 playlists from a specific search keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = dict()\n",
    "\n",
    "# {\n",
    "#   \"4ETxM0kkS3RMPveAijToRh\": {\n",
    "#     \"id\": \"4ETxM0kkS3RMPveAijToRh\",\n",
    "#     \"keywords\": {\n",
    "#       \"workout\": 12, # <<< associated rank in search result\n",
    "#       \"yoga\": 63\n",
    "#     },\n",
    "#     \"name\": \"The playlist name\",\n",
    "#     \"description\": \"The playlist description\"\n",
    "#   }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\" # cooking, running, shower, yoga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get 50 results per page, so we need 20 pages to get 1000 playlists\n",
    "for page in range(20):\n",
    "  print(f\"Keyword \\\"{keyword}\\\" | Page {page}\")\n",
    "\n",
    "  search_result = sp.search(\n",
    "    q=keyword,\n",
    "    limit=50,\n",
    "    offset=page*50,\n",
    "    type=\"playlist\",\n",
    "    # market=\"FR\"\n",
    "  )\n",
    "\n",
    "  for idx, playlist in enumerate(search_result[\"playlists\"][\"items\"]):\n",
    "    id = playlist[\"id\"]\n",
    "    rank = idx + page*50\n",
    "    \n",
    "    if id in playlists.keys():\n",
    "      playlists[id][\"keywords\"][keyword] = rank\n",
    "\n",
    "    else:\n",
    "      playlists[id] = {\n",
    "        \"id\": id,\n",
    "        \"name\": playlist[\"name\"],\n",
    "        \"description\": playlist[\"description\"],\n",
    "        \"keywords\": {\n",
    "          keyword: rank\n",
    "        }\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the most relevant keyword as an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, value in playlists.items():\n",
    "  best_keyword = min(value[\"keywords\"], key=value[\"keywords\"].get)\n",
    "\n",
    "  value[\"best_kw\"] = best_keyword\n",
    "  value[\"best_kw_rank\"] = value[\"keywords\"][best_keyword]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store playlists on disk, as `dict` as well as `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.DataFrame(playlists).T.reset_index(drop=True)\n",
    "\n",
    "with open('data/playlists_dict.pkl', 'wb') as f:\n",
    "  pickle.dump(playlists, f)\n",
    "\n",
    "playlists_df.to_pickle(\"data/playlists_df.pkl.gz\", compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2: Retrieve tracks from the playlists we have (⚠️ very long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `playlists_df` to get their IDs.  \n",
    "If you load the playlists from a past computation, uncomment the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlists_df = pd.read_pickle(\"data/playlists_df.pkl.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = dict()\n",
    "\n",
    "# {\n",
    "#   \"7EW6TtHJIa2zyydF6dwNBs\": {\n",
    "#     \"id\": \"7EW6TtHJIa2zyydF6dwNBs\",\n",
    "#     \"name\": \"Track title\",\n",
    "#     \"artist\": \"Justin Bieber &&& Rihanna\",\n",
    "#     \"genres\": \"Rock\", # TODO Ex: Pop &&& Rock &&& Variété\n",
    "#     \"popularity\": 45,\n",
    "#     \"playlist_ids\": []\n",
    "#   }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionnary of track IDs from the playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tracks_from_playlist(playlist_id, n_page, all_tracks):\n",
    "  print(f\"Playlist \\\"{playlist_id}\\\" | Page {n_page+1}\")\n",
    "  \n",
    "  try:\n",
    "    playlist_tracks = sp.playlist_tracks(\n",
    "      playlist_id=playlist_id,\n",
    "      offset=n_page*100,\n",
    "      # market=\"FR\"\n",
    "    )\n",
    "  except:\n",
    "    return all_tracks, 0\n",
    "\n",
    "  for track in playlist_tracks[\"items\"]:\n",
    "    # On rare cases, the track is empty\n",
    "    if track[\"track\"] is None:\n",
    "      print(track)\n",
    "      continue\n",
    "\n",
    "    id = track[\"track\"][\"id\"]\n",
    "    \n",
    "    # If the track already exists, we just append the current playlist ID to the playlist_ids attribute\n",
    "    if id in all_tracks.keys():\n",
    "      all_tracks[id][\"playlist_ids\"].append(playlist_id)\n",
    "\n",
    "    # If the track does not exist, we build it\n",
    "    else:\n",
    "      all_tracks[id] = {\n",
    "        \"id\": id,\n",
    "        \"name\": track[\"track\"][\"name\"],\n",
    "        \"artists\": \" &&& \".join([artist[\"name\"] for artist in track[\"track\"][\"artists\"]]),\n",
    "        \"popularity\": track[\"track\"][\"popularity\"],\n",
    "        \"playlist_ids\": [playlist_id]\n",
    "      }\n",
    "  \n",
    "  return all_tracks, playlist_tracks[\"total\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for playlist_id in playlists_df[\"id\"]:\n",
    "  tracks, total_tracks = retrieve_tracks_from_playlist(playlist_id, 0, tracks)\n",
    "\n",
    "  # If the playlist contains more than 100 tracks, it's paginated.\n",
    "  # So we need to request the remaining pages the same way.\n",
    "  if total_tracks > 100:\n",
    "    total_pages = ceil(total_tracks / 100)\n",
    "    \n",
    "    for page in range(1, total_pages):\n",
    "      tracks, _ = retrieve_tracks_from_playlist(playlist_id, page, tracks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store tracks on disk as `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tracks_dict.pkl', 'wb') as f:\n",
    "  pickle.dump(tracks, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #3: Retrieve audio features from all the tracks we have (by batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `tracks_dict` to get their IDs.  \n",
    "If you load the tracks from a past computation, uncomment the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/tracks_dict.pkl', 'rb') as f:\n",
    "#   tracks = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = [key for key in tracks.keys() if key is not None]\n",
    "\n",
    "# Build batches of 100 tracks\n",
    "tracks_batches = [track_ids[i:i+100] for i in range(0, len(track_ids), 100)]\n",
    "\n",
    "# Retrieve audio features in one list\n",
    "audio_features = []\n",
    "\n",
    "for batch in tracks_batches:\n",
    "  audio_features += sp.audio_features(tracks=batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store audio features on disk, as `dict` as well as `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = [x for x in audio_features if x is not None]\n",
    "audio_features_df = pd.DataFrame(audio_features)\n",
    "\n",
    "with open('data/audio_features_dict.pkl', 'wb') as f:\n",
    "  pickle.dump(audio_features, f)\n",
    "\n",
    "audio_features_df.to_pickle(\"data/audio_features_df.pkl.gz\", compression=\"gzip\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efd95ccc608b77d294959e4b9db6fd403086a3a1d4083b70a366fc9163eb7152"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('spotipy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
